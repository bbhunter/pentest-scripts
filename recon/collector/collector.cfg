# Configuration file of collector script

# Colours
red="\e[31m"
green="\e[32m"
yellow="\e[33m"
reset="\e[0m"

# Letters
bold=$(tput bold)
normal=$(tput sgr0)

# Get date
date_recon=$(date +%Y%m%d)

# output dir
output_dir="${PWD}"

# List of directories
pentest_dir=""
wordlists_dir="${pentest_dir}/wordlists"
exploits_dir="${pentest_dir}/exploits"

# List of 3rd party binaries and python scripts to use in this script
amass_bin=$(command -v amass)
aquatone_bin=$(command -v aquatone)
dirsearch_bin=$(command -v dirsearch)
dnssearch_bin=$(command -v dnssearch)
gitdumper_bin=$(command -v git-dumper)
gobuster_bin=$(command -v gobuster)
html2text_bin=$(command -v html2text)
httpx_bin=$(command -v httpx)
massdns_bin=$(command -v massdns)
nmap_bin=$(command -v nmap)
nuclei_bin=$(command -v nuclei)
shodan_bin=$(command -v shodan)
subfinder_bin=$(command -v subfinder)
wayback_bin=$(command -v waybackurls)

# Get the correct path to use chromium with aquatone
for binary in chromium chromium-browser; do
    if [ -x "$(command -v ${binary})" ] ; then
       chromium_bin="$(command -v ${binary})"
    fi
done

# Tools parameters
aquatone_threads=5
# Determines the time in minutes of the execution
# of the amass our default is 5 minutes
amass_timeout_execution="5"
curl_agent="\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36\""
curl_timeout="1"
curl_options=(-A "${curl_agent}" -k -s --max-time "${curl_timeout}" --connect-timeout "${curl_timeout}")
dirsearch_threads=50
# Here a change the way We'll use the collector after several reports about issues using collector taking several hours running
# and doesn't stop, so I'm forcing the user to put a DNS the realy works and execute the collector like a charm.
# We have 3 DNS servers from Google and Cloudflare if you think that is shit  put others that you trust and know that works!
# You need to put at least ONE DNS!!!
# You can add editing this file or use the -r|--resolve option to append the DNS in dns_servers array
# You can add editing the collector.cfg or use the -r|--resolve option to append the DNS in dns_servers array (without comma between servers)!
# WITHOUT DNS THE COLLECTOR DOES NOT RUN!!!!
dns_servers=()
dns_resolvers_file="${wordlists_dir}/resolvers.txt"
gobuster_threads=50
IPv4_regex='((25[0-5]|2[0-4][0-9]|[01][0-9][0-9]|[0-9]{1,2})[.]){3}(25[0-5]|2[0-4][0-9]|[01][0-9][0-9]|[0-9]{1,2})'
IPv6_regex='([0-9a-fA-F]{0,4}:){1,7}'
nmap_default_options="-n --stats-every 3m --max-retries 1 --max-scan-delay 20 --max-rate 30 --defeat-rst-ratelimit -sS -Pn -p-"
nmap_furtive_options="-f --mtu 1400 -g53 -Ddecoy-ip1,decoy-ip2,your-own-ip,decoy-ip3,decoy-ip4"
nuclei_agent="\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36\""
nuclei_templates_dir="${exploits_dir}/nuclei-templates"
webdata_total_processes=10
web_extensions="7z,asp,asp~,aspx,aspx~,backup,bak,bkp,cache,cgi,conf,config,csv,db,html,htmlx,inc,jar,js,json,jsp,jsp~,lock,log,old,php,php~,py,py~,rar,rb,rb~,shtml,sql,sql~,sql.gz,sql.tar.gz,sql.zip,swp,swp~,tar,tar.bz2,tar.gz,txt,wadl,xml,zip"
web_get_status=(200 301 302 401 403 404 500 503)
web_port_short_detection=(80 443 8080 8443)
web_port_long_detection=(80 81 443 832 981 1010 1311 2083 2087 2095 2096 4712 5001 7000 7001 7002 7003 7004 7005 7006 7007 7008 7009 7010 7080 7230 7443 7474 8000 8001 8002 8003 8004 8005 8006 8007 8008 8009 8010 8011 8012 8013 8014 8040 8041 8042 8043 8044 8045 8046 8047 8048 8049 8050 8051 8052 8053 8054 8056 8057 8058 8059 8060 8061 8062 8063 8064 8065 8066 8067 8068 8069 8070 8071 8072 8073 8074 8075 8076 8077 8078 8079 8080 8081 8082 8083 8084 8085 8086 8087 8088 8089 8090 8091 8172 8118 8123 8172 8181 8222 8230 8243 8280 8281 8333 8443 8500 8770 8771 8772 8773 8774 8775 8776 8777 8778 8779 8780 8834 8880 8888 8983 9000 9001 9002 9043 9060 9080 9090 9091 9200 9610 9800 9981 9999 9443 12443)

# List of wordlists to use in this script
web_wordlists=("${web_tools_dir}/dirsearch/db/dicc.txt")
dns_wordlists=()

# APIs to emails discovery
# https://app.snov.io/
hunterio_api=""

# APIs to subdomain discovery
binaryedge_api_url="https://api.binaryedge.io/v2/query/domains/subdomain"
binaryedge_api_key=""
censys_api_url="https://censys.io/api/v1/search/certificates?="
censys_api_id=""
censys_api_secret=""
dnsdb_api_url="https://api.dnsdb.info/lookup/rrset/name"
dnsdb_api_key=""
hackertarget_url="https://api.hackertarget.com/hostsearch/?q="
riskiq_api_url="https://api.passivetotal.org/v2/enrichment/subdomains"
riskiq_api_key=""
riskiq_api_secret=""
securitytrails_api_url="https://api.securitytrails.com/v1/domain/"
securitytrails_api_key=""
shodan_use="no"
shodan_apikey=""
shodan_scan_total=1
shodan_just_scan_main_domain="yes"
virustotal_api_url="https://www.virustotal.com/vtapi/v2/domain/report?apikey="
virustotal_api_key=""
