#############################################################
#                                                           #
# This file is an essential part of collector's execution!  #
# And is responsible to get the functions:                  #
#                                                           #
#   * webapp_alive                                          #
#                                                           #
############################################################# 

webapp_alive(){
    if [ -s "${report_dir}/domains_alive.txt" ]; then
        echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Testing subdomains to know if it is or have web application... "

        if [ -n "${use_proxy}" ] && [ "${use_proxy}" == "yes" ]; then
            proxy_port=8118
            proxy_ports=$("${docker_bin}" ps -a 2> /dev/null | grep -E "privoxy.*0.0.0.0" | awk '{print $13}' | sed -e 's/-.*$//' | awk -F':' '{print $2}')

            while [[ "${proxy_ports[@]}" =~ "${proxy_port}" ]]; do
                (( proxy_port+=1 ))
            done

            "${docker_bin}" run -d --rm --name "hosts_alive_detect" -p "${proxy_port}:8118" privoxy > /dev/null 2>&1

            if [ "$(${docker_bin} ps -a 2> /dev/null | grep -E hosts_alive_detect | awk '{print $14}')" == "hosts_alive_detect" ]; then
                proxy="$(${docker_bin} inspect --format '{{ .NetworkSettings.IPAddress }}' "hosts_alive_detect" 2> /dev/null):${proxy_port}"
            fi

            if [[ -n "${proxy}" ]]; then                    
                if [ "${web_tool_detection}" == "curl" ]; then
                    alias curl="curl --proxy ${proxy}"
                fi
                if [ "${web_tool_detection}" == "httpx" ]; then
                    alias httpx="httpx -http-proxy ${proxy}"
                fi
            fi
        fi

        for subdomain in $(cat "${report_dir}/domains_alive.txt"); do
            if [ "${web_tool_detection}" == "curl" ]; then
                for port in "${web_port_detect[@]}"; do
                    subdomain_http_status_check=$(curl "${curl_options[@]}" -L -w "%{response_code}\n" "http://${subdomain}:${port}" -o /dev/null)
                    subdomain_https_status_check=$(curl "${curl_options[@]}" -L -w "%{response_code}\n" "https://${subdomain}:${port}" -o /dev/null)
                    if [[ "${subdomain_http_status_check}" -ne 400 ]] && [[ "${subdomain_http_status_check}" -ne 000 ]]; then
                        echo -e "http://${subdomain}:${port}\t${subdomain_http_status_check}" >> "${report_dir}/domains_web_status.txt"
                    fi
                    if [[ "${subdomain_https_status_check}" -ne 400 ]] && [[ "${subdomain_https_status_check}" -ne 000 ]]; then
                        echo -e "https://${subdomain}:${port}\t${subdomain_https_status_check}" >> "${report_dir}/domains_web_status.txt"
                    fi
                done
            fi
            if [ "${web_tool_detection}" == "httpx" ]; then
                echo "${subdomain}" | httpx -nc -silent -p $(echo "${web_port_detect[@]}" | sed 's/ /,/g') -status-code | \
                    sed 's/\[// ; s/]//' >> "${report_dir}/domains_web_status.txt"
            fi
        done

        if [ "$(${docker_bin} ps -a 2> /dev/null | grep -E hosts_alive_detect | awk '{print $14}')" == "hosts_alive_detect" ]; then
            if [ "${web_tool_detection}" == "curl" ]; then
                unalias curl
            fi

            if [ "${web_tool_detection}" == "httpx" ]; then
                unalias httpx
            fi
            unset proxy
            unset proxy_port
            unset proxy_ports
            "${docker_bin}" stop "hosts_alive_detect" > /dev/null 2>&1
        fi

        if [ -s "${report_dir}/domains_web_status.txt" ]; then
            echo "Done!"
            echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Separating web applications according to the HTTP Status Code defined in collector.cfg... "
            sed -i 's/\/\/$// ; s/:443// ; s/:80$// ; s/:80\t/\t/ ; s/\(:80\)\(\/\)/\2/ ; s/:\/$// ; s/\(\.\)\([[:alpha:]]*\)\(\/$\)/\1\2/' "${report_dir}/domains_web_status.txt"
            for page_status in "${web_get_status[@]}"; do
                if [[ "${page_status}" =~ "30" ]]; then
                    for url_redirected in $(grep -E "${page_status}$" "${report_dir}/domains_web_status.txt" | awk '{print $1}'); do
                        curl -kLs -o /dev/null -w "%{url_effective}\n" "${url_redirected}"
                    done
                fi
                grep -E "${page_status}$" "${report_dir}/domains_web_status.txt" | awk '{print $1}'
            done | sed -E 's/^http(|s):\/\/// ; s/:.*$//' | awk -F'/' '{print $1}' >> "${tmp_dir}/domains_web_tmp.txt"
            unset url_redirected

            if [ -s "${tmp_dir}/domains_web_tmp.txt" ]; then
                sort -u -o "${report_dir}/domains_web.txt" "${tmp_dir}/domains_web_tmp.txt"
            else
                echo "Fail!"
                echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Something got wrong while checking web status file!"
                exit 1
            fi
        else
            echo "Fail!"
            echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Something got wrong while checking the status of URLs!"
            exit 1
        fi

        if [ -s "${report_dir}/domains_web.txt" ]; then
            echo "Done!"
            echo -ne "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} Separating infrastructure from web application... "
            if cp "${report_dir}/domains_alive.txt" "${report_dir}/domains_infrastructure.txt"; then
                while IFS= read -r line; do
                    subdomain=$(echo "${line}" | sed -e "s/http:\/\///" -e "s/https:\/\///" | awk -F":" '{print $1}' | awk -F"/" '{print $1}')
                    if grep -q "${subdomain}" "${report_dir}/domains_infrastructure.txt" 2> ${log_dir}/recon_domain_error_${date_recon}.log ; then
                        sed -i "/^${subdomain}$/d" "${report_dir}/domains_infrastructure.txt"
                    else
                        continue
                    fi
                    unset subdomain
                done < "${report_dir}/domains_web.txt"
                echo "Done!"
            else
                echo "Fail!"
                echo "Could not create file for infrastructure domains, something went wrong."
                exit 1
            fi
        else
            echo "Fail!"
            echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} We probably didn't have any application with HTTP Status Code defined in collector.cfg, something is wrong!"
            exit 1
        fi

        if [ -f "${report_dir}/domains_web_status.txt" ] && [ -f "${report_dir}/domains_infrastructure.txt" ]; then
            echo -e "\t Probably we have: "
            echo -e "\t   * $(awk '{print $1}' "${report_dir}/domains_web_status.txt" | sed -e 's/^http.*\/\/// ; s/:.*$//' | awk -F'/' '{print $1}' | sort -u | wc -l) Web Applications URL(s)."
            echo -e "\t   * $(wc -l "${report_dir}/domains_infrastructure.txt" | awk '{print $1}') Infrastructure domain(s)."
        fi
    else
        echo -e "${yellow}$(date +%H:%M)${reset} ${red}>>${reset} webapp_alive function error: the ${report_dir}/domains_alive.txt does not exist or is empty."
        exit 1
    fi
}
